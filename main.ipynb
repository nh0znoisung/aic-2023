{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the KeyMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L04_V023.csv', 'L05_V023.csv', 'L19_V026.csv']\n",
      "738\n"
     ]
    }
   ],
   "source": [
    "map_keyframe_list = ['map-keyframes/*.csv']\n",
    "file_list_list = [glob.glob(folder_path) for folder_path in map_keyframe_list]\n",
    "file_list = list(chain(*file_list_list))\n",
    "\n",
    "\n",
    "csv_files = [file.split('/')[1]  for file in file_list]\n",
    "print(csv_files[:3])\n",
    "print(len(csv_files))\n",
    "\n",
    "# 738\n",
    "# Batch 1: 299\n",
    "# Batch 2: 439\n",
    "# Frame index ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0005'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{5:04}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0012'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"keyframes/L01_V001/{:04}.jpg\".format(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = []\n",
    "for csv_file in csv_files:\n",
    "    video_name = csv_file.split('.csv')[0]\n",
    "    csv_file_path = os.path.join('map-keyframes', csv_file)\n",
    "\n",
    "    # Read the CSV file and extract the 'frame_idx' values\n",
    "    with open(csv_file_path, 'r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            frame_idx = row['frame_idx']\n",
    "            n = int(row['n'])\n",
    "            path = \"keyframes/{}/{:04}.jpg\".format(video_name, n)\n",
    "            merged_data.append({'video_name': video_name, 'frame_idx': frame_idx, 'n': n, 'path': path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file saved to merged_keyframes.csv\n"
     ]
    }
   ],
   "source": [
    "output_csv_path = 'merged_keyframes.csv'\n",
    "# Write the merged data to a new CSV file\n",
    "with open(output_csv_path, 'w', newline='') as output_file:\n",
    "    fieldnames = ['video_name', 'frame_idx', 'n', 'path']\n",
    "    csv_writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(merged_data)\n",
    "\n",
    "print(f'Merged CSV file saved to {output_csv_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7658"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_keyframes.csv')\n",
    "df.head(5)\n",
    "filtered_df = df[df['video_name'].str.contains('L01_')]\n",
    "len(filtered_df)\n",
    "# filtered_df.to_csv('merged_keyframes1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202148\n",
      "    video_name  frame_idx  n                         path\n",
      "961   L01_V001          0  1  keyframes/L01_V001/0001.jpg\n",
      "962   L01_V001        100  2  keyframes/L01_V001/0002.jpg\n",
      "963   L01_V001        271  3  keyframes/L01_V001/0003.jpg\n",
      "964   L01_V001        335  4  keyframes/L01_V001/0004.jpg\n",
      "965   L01_V001        346  5  keyframes/L01_V001/0005.jpg\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('merged_keyframes.csv')\n",
    "print(len(df))\n",
    "\n",
    "df = df.sort_values(by=['video_name', 'frame_idx'])\n",
    "print(df.head(5))\n",
    "\n",
    "df.to_csv('merged_keyframes.csv', index=False)\n",
    "\n",
    "# 100 / 202148 = thấp\n",
    "# 202.148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10584.194809949127"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400.962482213974/7658*202148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9400541138747576"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10584.194809949127 / 60 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('merged_keyframes.csv')\n",
    "\n",
    "for i in range(10,12):\n",
    "    query_df = df.sample(n=100, random_state=42)\n",
    "    query_df.to_csv(f'query-p1-{i}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More advanced approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>frame_idx</th>\n",
       "      <th>n</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L01_V001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>keyframes/L01_V001/0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L01_V001</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>keyframes/L01_V001/0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L01_V001</td>\n",
       "      <td>271</td>\n",
       "      <td>3</td>\n",
       "      <td>keyframes/L01_V001/0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L01_V001</td>\n",
       "      <td>335</td>\n",
       "      <td>4</td>\n",
       "      <td>keyframes/L01_V001/0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L01_V001</td>\n",
       "      <td>346</td>\n",
       "      <td>5</td>\n",
       "      <td>keyframes/L01_V001/0005.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_name  frame_idx  n                         path\n",
       "0   L01_V001          0  1  keyframes/L01_V001/0001.jpg\n",
       "1   L01_V001        100  2  keyframes/L01_V001/0002.jpg\n",
       "2   L01_V001        271  3  keyframes/L01_V001/0003.jpg\n",
       "3   L01_V001        335  4  keyframes/L01_V001/0004.jpg\n",
       "4   L01_V001        346  5  keyframes/L01_V001/0005.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('merged_keyframes.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 236\n",
    "# 249"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lap13528/anaconda3/envs/lavis/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from lavis.models import load_model_and_preprocess\n",
    "from lavis.processors import load_processor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model, vis_processors, text_processors = load_model_and_preprocess(\"blip_image_text_matching\", \"large\", device=device, is_eval=True)\n",
    "# model, vis_processors, text_processors = load_model_and_preprocess(\"blip_image_text_matching\", \"base\", device=device, is_eval=True)\n",
    "# model, vis_processors, text_processors = load_model_and_preprocess(\"blip2_image_text_matching\", \"pretrain\", device=device, is_eval=True)\n",
    "# model, vis_processors, text_processors = load_model_and_preprocess(\"blip2_image_text_matching\", \"coco\", device=device, is_eval=True)\n",
    "\n",
    "def get_score(path: str, caption: str):\n",
    "    # \"../docs/_static/merlion.png\"\n",
    "    # caption = \"that is dog\"\n",
    "    raw_image = Image.open(path).convert(\"RGB\")\n",
    "    img = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "    txt = text_processors[\"eval\"](caption)\n",
    "\n",
    "    itm_output = model({\"image\": img, \"text_input\": txt}, match_head=\"itm\")\n",
    "    itm_scores = torch.nn.functional.softmax(itm_output, dim=1)\n",
    "    score = itm_scores[:, 1].item()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/z6f74d2n4rg3n9z6h4vr3fc40000gn/T/ipykernel_44519/1067779583.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp['score'] = tmp['path'].apply(lambda path: get_score(path, caption))\n"
     ]
    }
   ],
   "source": [
    "caption = \"The video clip shows a woman wearing a yellow shirt disposing of trash into a garbage bin. The garbage bin is dark green, and its lid is red. The trash being placed into the bin appears to be 1 kilogram of baby spinach.\"\n",
    "df['score'] = df['path'].apply(lambda path: get_score(path, caption))\n",
    "\n",
    "result = df.sort_values(by='score', ascending=False)\n",
    "print(result.head(10))\n",
    "\n",
    "result.to_csv('submission/', index=False)\n",
    "result[['video_name', 'frame_idx']].to_csv('submission/', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"Read caption from file\")\n",
    "parser.add_argument(\"--caption\", help=\"Path argument of caption\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "caption_path = args.caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 folder queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('queries/query-1.txt', \"r\") as file:\n",
    "    file_contents = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Đoạn video về một người phụ nữ mặc áo màu vàng đang bỏ rác vào thùng rác. Thùng rác màu xanh lá đậm và nắp thùng màu đỏ. Rác đang bỏ vào thùng cho biết đó là 1kg baby spinach.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
